{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Package"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import csv\r\n",
    "from socket import MSG_MCAST\r\n",
    "from urllib.parse import quote, quote_plus\r\n",
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import pandas as pd\r\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ë‚ ì§œ ì§€ì •"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "strDate = '20200901' # ì‹œì‘ ë‚ ì§œ\r\n",
    "endDate = '20200930' # ì¢…ë£Œ ë‚ ì§œ"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CSV ì €ì¥"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filename = f\"daum_news_{strDate}-{endDate}.csv\"\r\n",
    "f = open(filename, \"w\", encoding=\"utf-8-sig\", newline=\"\")\r\n",
    "writer = csv.writer(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ìœ ì € ì—ì´ì „íŠ¸ ì§€ì •\r\n",
    "> [WhatismyUserAgent(ctrl+ğŸ–± í›„ í™•ì¸)](https://www.whatismybrowser.com/detect/what-is-my-user-agent)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "headers = {\"User-Agent\" : \"ê°œì¸ ìœ ì € ì—ì´ì „íŠ¸\"}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ë°˜ë³µë¬¸ì— ë“¤ì–´ê°ˆ ë‚ ì§œ ì§€ì •"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dt_index = pd.date_range(start=strDate, end=endDate)\r\n",
    "dt_list = dt_index.strftime(\"%Y%m%d\").tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ìŠ¤í¬ë˜í•‘ ì‹œì‘"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in dt_list:\r\n",
    "    print('ë‚ ì§œ',i)\r\n",
    "    page_url = f\"https://news.daum.net/breakingnews/?page=10000&regDate={i}\"\r\n",
    "    page =requests.get(page_url, headers=headers)\r\n",
    "    page_soup = BeautifulSoup(page.text, \"lxml\")\r\n",
    "    last_page = page_soup.find(\"em\", attrs=\"num_page\").get_text()\r\n",
    "    lastPage_num = re.sub(r'[^0-9]','',last_page)\r\n",
    "    # print(lastPage_num)\r\n",
    "\r\n",
    "    for j in range(1, int(lastPage_num)+1):\r\n",
    "        main_url = f\"https://news.daum.net/breakingnews/?page={j}&regDate={i}\" # url ì…ë ¥\r\n",
    "        res = requests.get(main_url, headers=headers)\r\n",
    " \r\n",
    "        if res.status_code == 200:\r\n",
    "            print(i, int(lastPage_num), 'ì¤‘' ,j,'page',round(j/int(lastPage_num)*100, 2),'%', main_url, 'status:',res.status_code)\r\n",
    "            soup = BeautifulSoup(res.text, \"lxml\") # soupìœ¼ë¡œ ì €ì¥\r\n",
    "            main = soup.find(\"ul\", attrs={\"class\":\"list_news2 list_allnews\"})\r\n",
    "            news = main.find_all(\"strong\", attrs={\"class\":\"tit_thumb\"})\r\n",
    "            cnt = 0\r\n",
    "            for new in news:\r\n",
    "                urls = new.select_one(\"a\")[\"href\"]# í˜ì´ì§€ì— ë‚˜ì™€ìˆëŠ” ë‰´ìŠ¤ URL ë³€ìˆ˜ ì…ë ¥\r\n",
    "                # print(urls)\r\n",
    "                result = requests.get(urls, headers=headers)         # request ë¡œ ë‹¤ì‹œ ê°œë³„ ë‰´ìŠ¤ ì ‘ì†\r\n",
    "                if result.status_code == 200:\r\n",
    "                    news_soup = BeautifulSoup(result.text, \"lxml\")\r\n",
    "                    # ë‰´ìŠ¤ ì œëª©, ë°œí–‰ì‹œê°„, ê¸°ì‚¬ë³¸ë¬¸ ì €ì¥\r\n",
    "                    title = news_soup.find(\"h3\", attrs={\"tit_view\"}).get_text().strip()\r\n",
    "                    pubdate = news_soup.find(\"span\", attrs={\"num_date\"}).get_text().strip()\r\n",
    "                    text = news_soup.find(\"div\", attrs={\"news_view\"}).get_text().strip()\r\n",
    "                    cnt += 1\r\n",
    "                    # print(j,'of',cnt,'ë²ˆì§¸ ê¸°ì‚¬')\r\n",
    "                    # print(i,j,'of',cnt,'ë²ˆì§¸ ê¸°ì‚¬', urls,'status:', result.status_code)\r\n",
    "                    writer.writerow([cnt, title, pubdate, urls, text])\r\n",
    "                else:\r\n",
    "                    print(i,j,'of',cnt,'ë²ˆì§¸ ê¸°ì‚¬','error_code :',result.status_code, urls)\r\n",
    "                    pass\r\n",
    "                   \r\n",
    "        else:\r\n",
    "            print(i,'page : ',j,'error_code :',res.status_code, main_url)\r\n",
    "            pass"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.4 64-bit"
  },
  "interpreter": {
   "hash": "4c65b98e956c6ae24f8ae0bc56d1e465ff92310dbdec0a4bd6b48ffdf1441c98"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}